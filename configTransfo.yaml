data:
  root_dir: '/mounts/Datasets3/2024-2025-ChallengePlankton/'
  trainpath: '/mounts/Datasets3/2024-2025-ChallengePlankton/train/'
  testpath: '/mounts/Datasets3/2024-2025-ChallengePlankton/test/'
  batch_size: 64  # Réduit pour éviter OOM avec SwinV2-Small
  num_workers: 8
  valid_ratio: 0.1
  patch_size: [256, 256]  # Adapté pour SegFormer
  quick_test: False
  transform_type: "medium-best"

optim:
  algo: AdamW
  params:
    lr: 0.0003  # Transformers nécessitent un LR plus bas que CNNs
    weight_decay: 0.0001  # Moins de régularisation pour éviter underfitting

scheduler:
  class: CosineAnnealingWarmRestarts
  params:
    T_0: 7  # Augmenté pour une convergence stable
    T_mult: 2
    eta_min: 1e-6

nepochs: 30  # Plus d'epochs pour compenser la convergence plus lente des transformers
pos_weight: 1

loss:
  name: "TverskyLoss"
  alpha: 0.6
  beta: 0.4

logging:
  wandb:
    project: "ChallengePlankton"
    entity: "Random_Predictions_2"
  logdir: "./logs"

model:
  class: Segformer  # SegFormer utilisé avec Swin
  encoder:
    model_name: "tu-swinv2_small_window8_256"  # SwinV2-Small comme backbone
  decoder_segmentation_channels: 256  # SegFormer utilise une segmentation améliorée
  in_channels: 1  # Images en niveaux de gris
  classes: 1  # Segmentation binaire

test:
  model_path: 'logs/SegFormer_SwinV2-Small/'
  model_name: 'best_model.pt'
  model_config: 'config.yaml'

# Changements :
# 1. **SegFormer** au lieu de Unet++ ou DeepLabV3+ (meilleur avec Transformer)
# 2. **SwinV2-Small** comme backbone (équilibre entre précision et consommation VRAM)
# 3. **LR réduit (0.0003)** pour stabiliser le training des transformers
# 4. **TverskyLoss** pour améliorer la segmentation des petits objets
# 5. **Patchs 256x256** pour éviter de saturer la VRAM
# 6. **Plus d'epochs (30)** pour une meilleure convergence
